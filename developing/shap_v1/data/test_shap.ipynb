{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/oscarwu/code/chemprop_developing')\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>logSolubility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CC#N</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  smiles  logSolubility\n",
       "7   CC#N           0.26"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load an example\n",
    "df_smi = pd.read_csv('esol.csv')\n",
    "df_smi.iloc[[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = df_smi.iloc[[7]]['smiles'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC#N']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemprop.features.utils import load_features, load_valid_atom_or_bond_features\n",
    "from chemprop.models.mpn import mask_features_extra_batch, mask_features_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bond_features = [load_valid_atom_or_bond_features('esol_wb97xd_bond_RBF_features.pkl', smiles)[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "atom_descriptors = [load_valid_atom_or_bond_features('esol_wb97xd_atom_RBF_features.pkl', smiles)[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_features = [load_features(\"esol_wb97xd_molecule_features.csv\")[7].reshape(1, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.atom_descriptors_layer.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.atom_descriptors_layer.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Loading pretrained parameter \"readout.7.weight\".\n",
      "Loading pretrained parameter \"readout.7.bias\".\n"
     ]
    }
   ],
   "source": [
    "from chemprop.args import TrainArgs\n",
    "from chemprop.models.model import MoleculeModel\n",
    "\n",
    "import torch\n",
    "from chemprop.utils import load_checkpoint, load_scalers\n",
    "from chemprop.features import set_extra_bond_fdim\n",
    "\n",
    "path = \"/home/oscarwu/code/chemprop_developing/developing/shap_v1/data/model.pt\"\n",
    "state = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "train_args = TrainArgs()\n",
    "train_args.from_dict(vars(state[\"args\"]), skip_unsettable=True)\n",
    "set_extra_bond_fdim(train_args.bond_features_size)\n",
    "model = load_checkpoint(path)\n",
    "scalers = load_scalers(path)\n",
    "target_scaler, mol_feature_scaler, _, _, _ = scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained parameter \"encoder.encoder.0.cached_zero_vector\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_i.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_h.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.W_o.bias\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.atom_descriptors_layer.weight\".\n",
      "Loading pretrained parameter \"encoder.encoder.0.atom_descriptors_layer.bias\".\n",
      "Loading pretrained parameter \"readout.1.weight\".\n",
      "Loading pretrained parameter \"readout.1.bias\".\n",
      "Loading pretrained parameter \"readout.4.weight\".\n",
      "Loading pretrained parameter \"readout.4.bias\".\n",
      "Loading pretrained parameter \"readout.7.weight\".\n",
      "Loading pretrained parameter \"readout.7.bias\".\n"
     ]
    }
   ],
   "source": [
    "# Example SHAP Analysis\n",
    "# Imports\n",
    "from chemprop.args import TrainArgs\n",
    "from chemprop.models.model import MoleculeModel\n",
    "\n",
    "import torch\n",
    "from chemprop.utils import load_checkpoint, load_scalers\n",
    "from chemprop.features import set_extra_bond_fdim\n",
    "\n",
    "from rdkit import Chem\n",
    "from chemprop.rdkit import make_mol\n",
    "\n",
    "# Load TrainArgs and MoleculeModel\n",
    "path = \"/home/oscarwu/code/chemprop_developing/developing/shap_v1/data/model.pt\"\n",
    "state = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "train_args = TrainArgs()\n",
    "train_args.from_dict(vars(state[\"args\"]), skip_unsettable=True)\n",
    "set_extra_bond_fdim(train_args.bond_features_size)\n",
    "model = load_checkpoint(path)\n",
    "scalers = load_scalers(path)\n",
    "\n",
    "# Create a MoleculeModel Wrapper\n",
    "class MoleculeModelWrapper:\n",
    "    def __init__(self, model, train_args, scalers, smiles, shap, features_batch, \n",
    "                 atom_descriptors_batch, atom_features_batch, bond_descriptors_batch, bond_features_batch):\n",
    "        self.model = model\n",
    "        self.train_args = train_args\n",
    "        self.target_scaler, self.mol_feature_scaler, _, _, _ = scalers\n",
    "        self.smiles = smiles\n",
    "        self.shap = shap\n",
    "        if features_batch is not None:\n",
    "            self.features_batch = [self.mol_feature_scaler.transform(feat) for feat in features_batch]\n",
    "        else:\n",
    "            self.features_batch = None      \n",
    "        self.atom_descriptors_batch = atom_descriptors_batch\n",
    "        self.atom_features_batch = atom_features_batch\n",
    "        self.bond_descriptors_batch = bond_descriptors_batch\n",
    "        self.bond_features_batch = bond_features_batch\n",
    "        \n",
    "        self.batch = None\n",
    "        self.extra_keep_features_batch = None\n",
    "        self.extra_atom_keep_descriptors_batch = None\n",
    "        self.extra_bond_keep_descriptors_batch = None\n",
    "        self.extra_atom_keep_features_batch = None\n",
    "        self.extra_bond_keep_features_batch = None\n",
    "        self.chemprop_atom_keep_features = None\n",
    "        self.chemprop_bond_keep_features = None\n",
    "        \n",
    "\n",
    "    def __call__(self, feature_choices):\n",
    "        if isinstance(feature_choices, np.ndarray):\n",
    "            if len(feature_choices.shape) == 1:\n",
    "                feature_choices = feature_choices.reshape(1, -1)\n",
    "                \n",
    "        result = []\n",
    "        \n",
    "        for feature_choice in feature_choices:\n",
    "        \n",
    "            self.batch = [[make_mol(s=smi, keep_h=True, add_h=True, keep_atom_map=True)] for smi in self.smiles]\n",
    "            self.extra_keep_features_batch = [feature_choice[0:20]] # 20 extra molecular features\n",
    "            self.extra_atom_keep_descriptors_batch = [feature_choice[20:33]] # 13 atom descriptors\n",
    "            self.extra_bond_keep_descriptors_batch = None # 0 bond descriptors\n",
    "            self.extra_atom_keep_features_batch = None # 0 atom features\n",
    "            self.extra_bond_keep_features_batch = [feature_choice[33:37]] # 4 bond features\n",
    "            self.chemprop_atom_keep_features = feature_choice[37:45] # 8 chemprop atom features\n",
    "            self.chemprop_bond_keep_features = feature_choice[45:49] # 4 chemprop bond features\n",
    "            \n",
    "            # this is from forward in original MoleculeModel in model.py\n",
    "            \n",
    "\n",
    "            output = self.model(batch=self.batch, \n",
    "                                features_batch=self.features_batch, \n",
    "                                atom_descriptors_batch=self.atom_descriptors_batch, \n",
    "                                atom_features_batch=self.atom_features_batch, \n",
    "                                bond_descriptors_batch=self.bond_descriptors_batch, \n",
    "                                bond_features_batch=self.bond_features_batch, \n",
    "                                constraints_batch=None,\n",
    "                                bond_types_batch=None,\n",
    "                                shap=self.shap, \n",
    "                                extra_keep_features_batch=self.extra_keep_features_batch, \n",
    "                                extra_atom_keep_descriptors_batch=self.extra_atom_keep_descriptors_batch, \n",
    "                                extra_bond_keep_descriptors_batch=self.extra_bond_keep_descriptors_batch, \n",
    "                                extra_atom_keep_features_batch=self.extra_atom_keep_features_batch, \n",
    "                                extra_bond_keep_features_batch=self.extra_bond_keep_features_batch, \n",
    "                                chemprop_atom_keep_features=self.chemprop_atom_keep_features, \n",
    "                                chemprop_bond_keep_features=self.chemprop_bond_keep_features)\n",
    "        \n",
    "            xform = self.target_scaler.inverse_transform(output.item()).item()\n",
    "            xform = np.array(xform, ndmin=2)\n",
    "            result.append(xform)\n",
    "        \n",
    "        return np.array(result).reshape(len(feature_choices), -1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wrapper = MoleculeModelWrapper(model=model, \n",
    "                                     train_args=train_args, \n",
    "                                     scalers=scalers, \n",
    "                                     smiles=smiles, \n",
    "                                     shap=True, \n",
    "                                     features_batch=mol_features, \n",
    "                                     atom_descriptors_batch=atom_descriptors, \n",
    "                                     atom_features_batch=None, \n",
    "                                     bond_descriptors_batch=None, \n",
    "                                     bond_features_batch=bond_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_choice = np.array([[1]*49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_wrapper(feature_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12861232]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_choice = np.array([[1]*49, [0]*49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model_wrapper(feature_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22396754],\n",
       "       [-2.12092157]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why this one is not determinstic?\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP\n",
    "from shap import PermutationExplainer\n",
    "from copy import deepcopy\n",
    "\n",
    "def binary_masker(binary_mask, x):\n",
    "    masked_x = deepcopy(x)\n",
    "    masked_x[binary_mask == 0] = 0\n",
    "    return np.array([masked_x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = PermutationExplainer(model=model_wrapper, masker=binary_masker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_choice = np.array([[1]*49])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = explainer(feature_choice, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".values =\n",
       "array([[ 0.12399631,  0.17350465, -0.10286548,  0.0998468 ,  0.02144805,\n",
       "         0.25611266,  0.00431325,  0.16269468,  0.25956138, -0.10789364,\n",
       "        -0.05849389,  0.03715444,  0.18857313,  0.16352001,  0.17327985,\n",
       "        -0.13776386,  0.54241898,  0.3498981 , -0.00112738, -0.03320775,\n",
       "        -0.03284645, -0.22548681, -0.06831403,  0.37020933,  0.08336058,\n",
       "         0.25049161,  0.1124818 ,  0.18074484,  0.30318643,  0.03711038,\n",
       "        -0.12214687, -0.13151167,  0.07588832, -0.09166334,  0.30452332,\n",
       "        -0.25006745,  0.32522174,  0.1984153 ,  0.22791068, -0.01503981,\n",
       "        -0.00467726, -0.25085408,  0.19395652, -0.58283483,  0.01010997,\n",
       "        -0.1969124 , -0.03054219,  0.30328642, -0.20927644]])\n",
       "\n",
       ".base_values =\n",
       "array([[-2.10869557]])\n",
       "\n",
       ".data =\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
